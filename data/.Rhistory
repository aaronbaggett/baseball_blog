rel_freq = prop.table(Freq), rel_percent = cumsum(prop.table(Freq))*100))
(violent_crime_freqs <- transform(violent_crime_freqs, cumFreq = cumsum(Freq),
rel_freq = prop.table(Freq), rel_percent = prop.table(Freq)*100))
(violent_crime_freqs <- transform(violent_crime_freqs, cumFreq = cumsum(Freq),
rel_freq = prop.table(Freq), rel_percent = cumsum(prop.table(Freq)*100))
)
(violent_crime_freqs <- transform(violent_crime_freqs, cumFreq = cumsum(Freq),
rel_freq = prop.table(Freq), rel_percent = cumsum(prop.table(Freq))*100))
(violent_crime_freqs <- transform(violent_crime_freqs, cumFreq = cumsum(Freq)))
real_range <- function(x){
(max(x) - min(x)) + 1
}
violent_crime_range <- real_range(violent_crimes)
int_width <- round(violent_crime_range / 10)
violent_crime_intervals <- factor(cut(violent_crimes, breaks = int_width))
(violent_crime_freqs <- as.data.frame(table(violent_crime_intervals)))
(violent_crime_freqs <- transform(violent_crime_freqs, cumFreq = cumsum(Freq)))
(violent_crime_freqs <- transform(violent_crime_freqs, cumFreq = cumsum(Freq), rel_freq = prop.table(Freq)))
(violent_crime_freqs <- transform(violent_crime_freqs, cumFreq = cumsum(Freq),
rel_freq = prop.table(Freq), rel_percent = cumsum(prop.table(Freq))*100))
(violent_crime_freqs <- transform(violent_crime_freqs, cumFreq = cumsum(Freq),
rel_freq = prop.table(Freq), rel_percent = prop.table(Freq)*100))
real_range <- function(x){
(max(x) - min(x)) + 1
}
violent_crimes <- violent_crimes$violent_crimes
violent_crime_range <- real_range(violent_crimes)
int_width <- round(violent_crime_range / 10)
violent_crime_intervals <- factor(cut(violent_crimes, breaks = int_width))
(violent_crime_freqs <- as.data.frame(table(violent_crime_intervals)))
### 1. Download the `coll_health.csv` data file and read it into RStudio using the Tools > Import Data Set... menu.  The data file is located in `myCourses` under Data Files.  Be sure to paste below the syntax that appears in the \textsf{R} Console after reading in the `coll_health` data frame.  Note: The syntax should resemble the following: `coll_health <- read.csv("~/file/path/coll_health.csv")` (1 pt.).
coll_health <- read.csv("~/Dropbox/UMHB/Teaching/Spring 2015/PSYC 2305/IDEAS/idea_02/college_health.csv")
### 2. It may help to use the `attach()` function to manually store the `coll_health` data frame in your current \textsf{R} session.  This allows you to call on any of the variables in the data without using the `$` indexing operator (1 pt.).
attach(coll_health)
### 3. Use the `table()` function to calculate the frequencies for the `exercise` and `sleep` variables (2 pts.).
table(exercise)
table(sleep)
### 4. Use the `quantile()` function to calculate the perentile point at the percentage of your choice (i.e, 0.01--0.99) for the `gpa` variable (2 pts.).
quantile(gpa, probs = 0.23)
### 5. Use the `quantile()` function to calculate the perentile rank at the 0.10--1 range with intervals equal to 0.10 for the `gpa` variable (2 pts.).
quantile(gpa, probs = seq(0.10, 1, 0.10))
### 6. Construct a frequency distribution for the `stress` variable (5 pts.).
real_range <- function(x){
(max(x) - min(x)) + 1
}
stress_range <- real_range(stress)
int_width <- round(stress_range / 10)
stress_intervals <- cut(stress, breaks = int_width)
(stress_freqs <- as.data.frame(table(stress_intervals)))
(stress_freqs <- transform(stress_freqs, rel_feq = prop.table(Freq),
cum_percent = cumsum(prop.table(Freq))))
### 7. Using the `ggplot()` function in the `ggplot2` package, construct a histogram with binwidth = 2 for the `bmi` variable (5 pts.).
ggplot(data = coll_health, aes(x = bmi)) +
geom_histogram(binwidth = 2, color = "white")
### 8. Construct an additional histogram with binwidth = 0.10 for the `gpa` variable (5 pts.).
ggplot(data = coll_health, aes(x = gpa)) +
geom_histogram(binwidth = 0.10, color = "white")
coll_health <- read.csv("~/Dropbox/UMHB/Teaching/Spring 2015/PSYC 2305/IDEAS/idea_02/college_health.csv")
coll_health <- read.csv("~/Dropbox/UMHB/Teaching/Spring 2015/PSYC 2305/IDEAS/idea_02/coll_health.csv")
### 1. Download the `coll_health.csv` data file and read it into RStudio using the Tools > Import Data Set... menu.  The data file is located in `myCourses` under Data Files.  Be sure to paste below the syntax that appears in the \textsf{R} Console after reading in the `coll_health` data frame.  Note: The syntax should resemble the following: `coll_health <- read.csv("~/file/path/coll_health.csv")` (1 pt.).
coll_health <- read.csv("~/Dropbox/UMHB/Teaching/Spring 2015/PSYC 2305/IDEAS/idea_02/coll_health.csv")
### 2. It may help to use the `attach()` function to manually store the `coll_health` data frame in your current \textsf{R} session.  This allows you to call on any of the variables in the data without using the `$` indexing operator (1 pt.).
attach(coll_health)
### 3. Use the `table()` function to calculate the frequencies for the `exercise` and `sleep` variables (2 pts.).
table(exercise)
table(sleep)
### 4. Use the `quantile()` function to calculate the perentile point at the percentage of your choice (i.e, 0.01--0.99) for the `gpa` variable (2 pts.).
quantile(gpa, probs = 0.23)
### 5. Use the `quantile()` function to calculate the perentile rank at the 0.10--1 range with intervals equal to 0.10 for the `gpa` variable (2 pts.).
quantile(gpa, probs = seq(0.10, 1, 0.10))
### 6. Construct a frequency distribution for the `stress` variable (5 pts.).
real_range <- function(x){
(max(x) - min(x)) + 1
}
stress_range <- real_range(stress)
int_width <- round(stress_range / 10)
stress_intervals <- cut(stress, breaks = int_width)
(stress_freqs <- as.data.frame(table(stress_intervals)))
(stress_freqs <- transform(stress_freqs, rel_feq = prop.table(Freq),
cum_percent = cumsum(prop.table(Freq))))
### 7. Using the `ggplot()` function in the `ggplot2` package, construct a histogram with binwidth = 2 for the `bmi` variable (5 pts.).
ggplot(data = coll_health, aes(x = bmi)) +
geom_histogram(binwidth = 2, color = "white")
### 8. Construct an additional histogram with binwidth = 0.10 for the `gpa` variable (5 pts.).
ggplot(data = coll_health, aes(x = gpa)) +
geom_histogram(binwidth = 0.10, color = "white")
### 1. Download the `coll_health.csv` data file and read it into RStudio using the Tools > Import Data Set... menu.  The data file is located in `myCourses` under Data Files.  Be sure to paste below the syntax that appears in the \textsf{R} Console after reading in the `coll_health` data frame.  Note: The syntax should resemble the following: `coll_health <- read.csv("~/file/path/coll_health.csv")` (1 pt.).
coll_health <- read.csv("~/Dropbox/UMHB/Teaching/Spring 2015/PSYC 2305/IDEAS/idea_02/coll_health.csv")
### 2. It may help to use the `attach()` function to manually store the `coll_health` data frame in your current \textsf{R} session.  This allows you to call on any of the variables in the data without using the `$` indexing operator (1 pt.).
attach(coll_health)
### 3. Use the `table()` function to calculate the frequencies for the `exercise` and `sleep` variables (2 pts.).
table(exercise)
table(sleep)
### 4. Use the `quantile()` function to calculate the perentile point at the percentage of your choice (i.e, 0.01--0.99) for the `gpa` variable (2 pts.).
quantile(gpa, probs = 0.23)
### 5. Use the `quantile()` function to calculate the perentile rank at the 0.10--1 range with intervals equal to 0.10 for the `gpa` variable (2 pts.).
quantile(gpa, probs = seq(0.10, 1, 0.10))
### 6. Construct a frequency distribution for the `stress` variable (5 pts.).
real_range <- function(x){
(max(x) - min(x)) + 1
}
stress_range <- real_range(stress)
int_width <- round(stress_range / 10)
stress_intervals <- cut(stress, breaks = int_width)
(stress_freqs <- as.data.frame(table(stress_intervals)))
(stress_freqs <- transform(stress_freqs, rel_feq = prop.table(Freq),
cum_percent = cumsum(prop.table(Freq))))
### 7. Using the `ggplot()` function in the `ggplot2` package, construct a histogram with binwidth = 2 for the `bmi` variable (5 pts.).
library(ggplot2)
ggplot(data = coll_health, aes(x = bmi)) +
geom_histogram(binwidth = 2, color = "white")
### 8. Construct an additional histogram with binwidth = 0.10 for the `gpa` variable (5 pts.).
ggplot(data = coll_health, aes(x = gpa)) +
geom_histogram(binwidth = 0.10, color = "white")
tx_crimes <- read.csv("~/Dropbox/UMHB/Teaching/Spring 2015/PSYC 2305/Data/tx_crimes.csv")
attach(tx_crimes)
names(tx_crimes)
table(murder)
table(arson)
table(rape)
table(robbery)
table(violent_crime)
table(arson)
head(tx_crimes)
quantile(murder, probs = 0.23)
quantile(murder, probs = 0.88)
quantile(murder, probs = seq(0.10, 1, 0.10))
murder
murder_range <- real_range(murder)
int_width <- round(murder_range / 10)
murder_intervals <- cut(murder, breaks = int_width)
(murder_freqs <- as.data.frame(table(murder_intervals)))
(murder_freqs <- transform(murder_freqs, rel_feq = prop.table(Freq),
cum_percent = cumsum(prop.table(Freq))))
### 7. Using the `ggplot()` function in the `ggplot2` package, construct a histogram with binwidth = 2 for the `bmi` variable (5 pts.).
library(ggplot2)
ggplot(data = tx_crimes, aes(x = murder)) +
geom_histogram(binwidth = 10, color = "white")
ggplot(data = tx_crimes, aes(x = murder)) +
geom_histogram(binwidth = 20, color = "white")
head(tx_crimes)
ggplot(data = tx_crimes, aes(x = arson)) +
geom_histogram(binwidth = 20, color = "white")
ggplot(data = tx_crimes, aes(x = arson)) +
geom_histogram(binwidth = 10, color = "white")
ggplot(data = tx_crimes, aes(x = arson)) +
geom_histogram(binwidth = 100, color = "white")
ggplot(data = tx_crimes, aes(x = rape)) +
geom_histogram(binwidth = 10, color = "white")
ggplot(data = tx_crimes, aes(x = violent_crime)) +
geom_histogram(binwidth = 10, color = "white")
ggplot(data = tx_crimes, aes(x = violent_crime)) +
geom_histogram(binwidth = 1, color = "white")
ggplot(data = tx_crimes, aes(x = robbery)) +
geom_histogram(binwidth = 1, color = "white")
ggplot(data = tx_crimes, aes(x = robbery)) +
geom_histogram(binwidth = 10, color = "white")
ggplot(data = tx_crimes, aes(x = robbery)) +
geom_histogram(binwidth = 5, color = "white")
ggplot(data = tx_crimes, aes(x = robbery)) +
geom_histogram(binwidth = 2, color = "white")
ggplot(data = tx_crimes, aes(x = robbery)) +
geom_histogram(binwidth = .2, color = "white")
ggplot(data = tx_crimes, aes(x = arson)) +
geom_histogram(binwidth = 2, color = "white")
ggplot(data = tx_crimes, aes(x = arson)) +
geom_histogram(binwidth = 20, color = "white")
head(tx_crimes)
ggplot(data = tx_crimes, aes(x = prop_crime)) +
geom_histogram(binwidth = 20, color = "white")
ggplot(data = tx_crimes, aes(x = prop_crime)) +
geom_histogram(binwidth = 2, color = "white")
ggplot(data = tx_crimes, aes(x = prop_crime)) +
geom_histogram(binwidth =52, color = "white")
ggplot(data = tx_crimes, aes(x = prop_crime)) +
geom_histogram(binwidth = 5, color = "white")
ggplot(data = tx_crimes, aes(x = vehicle_theft)) +
geom_histogram(binwidth = 5, color = "white")
ggplot(data = tx_crimes, aes(x = murder)) +
geom_histogram(binwidth = 5, color = "white")
ggplot(data = tx_crimes, aes(x = murder)) +
geom_histogram(binwidth = 15, color = "white")
ggplot(data = tx_crimes, aes(x = rape)) +
geom_histogram(binwidth = 15, color = "white")
head(tx_crimes)
ggplot(data = tx_crimes, aes(x = pop)) +
geom_histogram(binwidth = 15, color = "white")
ggplot(data = tx_crimes, aes(x = larceny_theft)) +
geom_histogram(binwidth = 15, color = "white")
ggplot(data = tx_crimes, aes(x = larceny_theft)) +
geom_histogram(binwidth = 5, color = "white")
ggplot(data = tx_crimes, aes(x = agg_assault)) +
ggplot(data = tx_crimes, aes(x = agg_assault)) +
geom_histogram(binwidth = 5, color = "white")
ggplot(data = tx_crimes, aes(x = agg_assault)) +
geom_histogram(binwidth = 2, color = "white")
ggplot(data = tx_crimes, aes(x = agg_assault)) +
geom_histogram(binwidth = 3, color = "white")
ggplot(data = diamonds, aes(x = carat)) +
geom_histogram(binwidth = 3, color = "white")
ggplot(data = diamonds, aes(x = carat)) +
geom_histogram(binwidth = 0.10, color = "white")
ggplot(data = diamonds, aes(x = price)) +
geom_histogram(binwidth = 0.10, color = "white")
ggplot(data = diamonds, aes(x = price)) +
geom_histogram(binwidth = 100, color = "white")
ggplot(data = diamonds, aes(x = price)) +
geom_histogram(binwidth = 1000, color = "white")
ggplot(data = diamonds, aes(x = price)) +
geom_histogram(binwidth = 1000, fill = "dodgerblue", color = "white")
ggplot(data = diamonds, aes(x = price)) +
geom_histogram(binwidth = 1000, fill = "dodgerblue", color = "tomato")
ggplot(data = diamonds, aes(x = price)) +
geom_histogram(binwidth = 1000, fill = "dodgerblue", color = "white")
ggplot(data = diamonds, aes(x = price)) +
geom_histogram(binwidth = 1000, fill = "dodgerblue", color = "white") +
scale_x_continuous(breaks = seq(0, 20000, 1000), name = "\nDiamond Price")
ggplot(data = diamonds, aes(x = price)) +
geom_histogram(binwidth = 1000, fill = "dodgerblue", color = "white") +
scale_x_continuous(breaks = seq(0, 20000, 1000), name = "\nDiamond Price") +
scale_y_continuous(breaks = seq(0, 15000, 2000), name = "Frequency\n")
rm(list = ls())
tx_crimes
tx_crimes <- read.csv("~/Dropbox/UMHB/Teaching/Spring 2015/PSYC 2305/Data/tx_crimes.csv")
tx_crimes <- read.csv("~/Dropbox/UMHB/Teaching/Spring 2015/PSYC 2305/Data/tx_crimes.csv")
View(tx_crimes)
tx_crimes$violent_crime
attach(tx_crimes)
violent_crime
table(murder)
quantile(murder, probs = 0.88)
quantile(murder, probs = seq(0.10, 1, 0.10))
real_range <- function(x){
(max(x) - min(x)) +1
}
murder_range <- real_range(murder)
murder_range
int_width <- round(murder_range / 10)
murder_intervals <- cut(murder, breaks = int_width)
(murder_freqs <- as.data.frame(table(murder_intervals)))
ggplot(data = diamonds, aes(x = price)) + geom_histogram(binwdith = 1000)
ggplot(data = diamonds, aes(x = price)) +
geom_histogram(binwdith = 1000, fill = "dodgerblue", color = "white")
ggplot(data = diamonds, aes(x = price)) +
geom_histogram(binwdith = 1000, fill = "dodgerblue", color = "white") +
scale_x_continuous(breaks = seq(0, 20000, 1000), name = "\nDiamond Price")
ggplot(data = diamonds, aes(x = price)) +
geom_histogram(binwdith = 1000, fill = "dodgerblue", color = "white") +
scale_x_continuous(breaks = seq(0, 20000, 1000), name = "\nDiamond Price") +
scale_y_continuous(breaks = seq(0, 15000, 2000), name = "Frequency\n")
ggplot(data = diamonds, aes(x = price)) +
geom_histogram(binwidth = 1000, fill = "dodgerblue", color = "white") +
scale_x_continuous(breaks = seq(0, 20000, 1000), name = "\nDiamond Price") +
scale_y_continuous(breaks = seq(0, 15000, 2000), name = "Frequency\n")
library(dplyr)
library(ggplot2)
diamonds %>%
group_by(cut) %>%
summarize(mean_price = mean(price))
library(dplyr)
library(ggplot2)
load("~/Desktop/pfx_13.Rda")
sample_n(pfx_13, 10)
pfx_13[sample(nrow(pfx_13), 3), ]
pfx_samp <- pfx_13[sample(nrow(pfx_13), 300), ]
pfx_samp %>%
group_by(batter_name) %>%
select(batter_name, b_height, sz_top, player_sz_top, height_top,
sz_bot, player_sz_bot, height_bot)
### --- Add player sz limits by *b_height* --- ###
pfx_13 <- pfx_13 %>%
group_by(b_height) %>%
mutate(height_top = mean(sz_top) %>%
mutate(height_bot = mean(sz_bot)
pfx_13 <- pfx_13%>%
group_by(batter_name) %>%
mutate(player_sz_top = mean(sz_top) %>%
mutate(player_sz_bot, mean(sz_bot)
### --- Add player sz limits by *b_height* --- ###
pfx_13 <- pfx_13 %>%
group_by(b_height) %>%
mutate(height_top = mean(sz_top) %>%
mutate(height_bot = mean(sz_bot)
pfx_13 <- pfx_13 %>%
group_by(batter_name) %>%
mutate(player_sz_top = mean(sz_top) %>%
mutate(player_sz_bot, mean(sz_bot)
library(dplyr)
library(ggplot2)
library(dplyr)
library(ggplot2)
### --- Add player sz limits by *b_height* --- ###
pfx_13 <- pfx_13 %>%
group_by(b_height) %>%
mutate(height_top = mean(sz_top) %>%
mutate(height_bot = mean(sz_bot)
)
### --- Add player sz limits by *b_height* --- ###
pfx_13 <- pfx_13 %>%
group_by(b_height) %>%
mutate(height_top = mean(sz_top)) %>%
mutate(height_bot = mean(sz_bot))
pfx_13 <- pfx_13 %>%
group_by(batter_name) %>%
mutate(player_sz_top = mean(sz_top)) %>%
mutate(player_sz_bot, mean(sz_bot))
pfx_samp <- pfx_13[sample(nrow(pfx_13), 300), ]
pfx_samp %>%
group_by(batter_name) %>%
select(batter_name, b_height, sz_top, player_sz_top, height_top,
sz_bot, player_sz_bot, height_bot)
### --- Add player sz limits by *b_height* --- ###
pfx_13 <- pfx_13 %>%
group_by(b_height) %>%
mutate(height_top = mean(sz_top))
pfx_13 <- pfx_13 %>%
group_by(b_height) %>%
mutate(height_bot = mean(sz_bot))
pfx_13 <- pfx_13 %>%
group_by(batter_name) %>%
mutate(player_sz_top = mean(sz_top))
pfx_13 <- pfx_13 %>%
group_by(batter_name) %>%
mutate(player_sz_bot, mean(sz_bot))
pfx_samp <- pfx_13[sample(nrow(pfx_13), 300), ]
pfx_samp %>%
group_by(batter_name) %>%
select(batter_name, b_height, sz_top, player_sz_top, height_top,
sz_bot, player_sz_bot, height_bot)
with(pfx_samp, table(b_height, height_bot))
pfx_13 %>%
group_by(b_height) %>%
mutate(height_top = mean(sz_top))
### ----------------------------------------------------------------------------- ###
### --------------------- PITCHf/x Database Construction ------------------------ ###
### ----------------------------------------------------------------------------- ###
### --- Load package libraries (if necessary) --- ###
library(dplyr)
library(pitchRx)
### --- Set and create *pfx_13a* working directory --- ###
setwd("~/Dropbox/Umpire IRT Study/Data")
pfx_13_all <- src_sqlite("pfx_13.sqlite3")
### --- Convert *pfx_13_all* tables to standalone tables --- ###
# action <- tbl(pfx_13_all, "action")
atbat <- tbl(pfx_13_all, "atbat")
# coach <- tbl(pfx_13_all, "coach")
# game <- tbl(pfx_13_all, "game")
# media <- tbl(pfx_13_all, "media")
pitch <- tbl(pfx_13_all, "pitch")
# player <- tbl(pfx_13_all, "player")
# po <- tbl(pfx_13_all, "po")
# runner <- tbl(pfx_13_all, "runner")
umpire <- tbl(pfx_13_all, "umpire")
### --- Chaining operations for data munging (I hate that word tho!) --- ###
atbats <- atbat %>%
select(num, stand, b_height, batter_name, gameday_link) %>%
group_by(gameday_link)
atbats <- collect(atbats)
pitches <- pitch %>%
select(call = des, sz_top, sz_bot, px, pz, zone, num, count, gameday_link) %>%
filter(call == "Called Strike" | call == "Ball") %>%
group_by(gameday_link)
pitches <- collect(pitches)
umpires <- umpire %>%
select(umpire = name, gameday_link) %>%
filter(position == home) %>%
group_by(gameday_link)
umpires <- collect(umpires)
ps_abs <- left_join(pitches, atbats, by = c("num", "gameday_link"))
ps_abs_us <- left_join(ps_abs, umpires, by = "gameday_link", copy = TRUE)
pfx_13 <- tbl_df(as.data.frame(ps_abs_us, n = -1))
pfx_13 <- na.omit(pfx_13)
pfx_13 %>%
group_by(batter_name) %>%
mutate(player_sz_top = mean(sz_top))
pfx_samp <- pfx_13[sample(nrow(pfx_13), 300), ]
pfx_13 %>%
group_by(batter_name) %>%
mutate(player_sz_top = mean(sz_top))
pfx_samp <- pfx_samp %>%
group_by(batter_name) %>%
mutate(player_sz_top = mean(sz_top))
pfx_samp %>%
group_by(batter_name) %>%
select(batter_name, b_height, sz_top, player_sz_top)
pfx_samp <- pfx_samp %>%
group_by(batter_name) %>%
mutate(player_sz_top = mean(sz_top), player_sz_bot = mean(sz_bot))
pfx_samp %>%
group_by(batter_name) %>%
select(batter_name, b_height, sz_top, player_sz_top, sz_bot, player_sz_bot)
pfx_samp %>%
group_by(batter_name) %>%
select(batter_name, b_height, sz_top, player_sz_top, height_top,
sz_bot, player_sz_bot, height_bot)
pfx_samp <- pfx_samp %>%
group_by(batter_height) %>%
mutate(height_top = mean(sz_top), height_bot = mean(sz_bot))
pfx_samp %>%
group_by(batter_name) %>%
select(batter_name, b_height, sz_top, player_sz_top, height_top,
sz_bot, player_sz_bot, height_bot)
pfx_samp <- pfx_samp %>%
group_by(b_height) %>%
mutate(height_top = mean(sz_top), height_bot = mean(sz_bot))
pfx_samp %>%
group_by(batter_name) %>%
select(batter_name, b_height, sz_top, player_sz_top, height_top,
sz_bot, player_sz_bot, height_bot)
pfx_samp <- pfx_samp %>%
group_by(b_height) %>%
mutate(height_top = mean(sz_top), height_bot = mean(sz_bot))
pfx_samp %>%
group_by(batter_name) %>%
select(batter_name, b_height, sz_top, player_sz_top, height_top,
sz_bot, player_sz_bot, height_bot)
### --- Add player sz limits by *batter_name* and *b_height* --- ###
pfx_13 <- pfx_13 %>%
group_by(batter_name) %>%
mutate(player_sz_top = mean(sz_top), player_sz_bot = mean(sz_bot))
pfx_13 <- pfx_13 %>%
group_by(b_height) %>%
mutate(height_top = mean(sz_top), height_bot = mean(sz_bot))
pfx_13 %>%
group_by(batter_name) %>%
select(batter_name, b_height, sz_top, player_sz_top, height_top,
sz_bot, player_sz_bot, height_bot)
pfx_samp <- pfx_13[sample(nrow(pfx_13), 300), ]
pfx_samp %>%
group_by(batter_name) %>%
select(batter_name, b_height, sz_top, player_sz_top, height_top,
sz_bot, player_sz_bot, height_bot)
### --- Create *u_test* variable for umpire's decision [1 = correct] --- ###
# Ball radius = ((1.57*2 + 17) / 12) / 2
pfx_13$u_test <- with(pfx_13,
ifelse(call == "Ball" & px < -0.8110375 | px > 0.8110375 |
pz < player_sz_bot | pz > player_sz_top, 1,
ifelse(call == "Called Strike" & pz > player_sz_bot & pz < player_sz_top &
px >= -0.8110375 & px <= 0.8110375, 1,
ifelse(call == "Ball" & pz > player_sz_bot & pz < player_sz_top &
px > -0.8110375 & px < 0.8110375, 0,
ifelse(call == "Called Strike" & px < -0.8110375 | px > 0.8110375 |
pz < player_sz_bot | pz > player_sz_top, 0, 99)))))
with(pfx_13, mean(as.numeric(u_test)))
### --- Specify *count* advantages --- #
# 1. Add *bs_count* variable to indicate who has the advantage (p vs. b)
# Based on Marchi & Albert, 2014
pfx_13$bs_count <- with(pfx_13,
# 1.1 Neutral
ifelse(count == "0-0" | count == "1-0" |
count == "1-1" | count == "2-1", "neutral",
# 1.2 Batter
ifelse(count == "2-0" | count == "3-0" |
count == "3-1" | count == "3-2", "batter",
# 1.3 Pitcher
ifelse(count == "0-1" | count == "0-2" |
count == "1-2" | count == "2-2", "pitcher", 99)
)))
# 2. Convert *count* to factor
pfx_13$bs_count <- as.factor(pfx_13$bs_count)
### --- Respecify *zone* regions --- #
pfx_13$zone_reg <- with(pfx_13,
# 1. RHBs
ifelse(stand == "R" & zone == "1" |
stand == "R" & zone == "4" |
stand == "R" & zone == "7", "inner",
ifelse(stand == "R" & zone == "2" |
stand == "R" & zone == "5" |
stand == "R" & zone == "8", "middle",
ifelse(stand == "R" & zone == "3" |
stand == "R" & zone == "6" |
stand == "R" & zone == "9", "outer",
# 2. LHBs
ifelse(stand == "L" & zone == "1" |
stand == "L" & zone == "4" |
stand == "L" & zone == "7", "outer",
ifelse(stand == "L" & zone == "2" |
stand == "L" & zone == "5" |
stand == "L" & zone == "8", "middle",
ifelse(stand == "L" & zone == "3" |
stand == "L" & zone == "6" |
stand == "L" & zone == "9", "inner", "ball")))))))
# 3. Convert *zone* to factor
pfx_13$zone_reg <- as.factor(pfx_13$zone_reg)
### --- Relevel "zone_reg" to make "ball" reference group --- ###
pfx_13$zone_reg <- relevel(pfx_13 $zone_reg, ref = "ball")
### --- Relevel "bs_count" to make "neutral" reference group --- ###
pfx_13 $bs_count <- relevel(pfx_13 $bs_count, ref = "neutral")
pfx_13$h_dist <- with(pfx_13, ifelse(px < 0, px - (-0.87),
ifelse(px > 0, 0.87 - px, 99)))
pfx_13$h_mid <- (pfx_13$player_sz_top - pfx_13$player_sz_bot) / 2
pfx_13$h_mid <- pfx_13$h_mid + pfx_13$player_sz_bot
pfx_13$v_dist <- with(pfx_13, ifelse(pz < h_mid, player_sz_bot - pz,
ifelse(pz > h_mid, player_sz_top - pz, 99)))
### Read in 2013 umpire-level ###
u_df <- read.csv("umpires.csv")
u_df$umpire <- as.character(u_df$umpire)
pfx_13 <- inner_join(pfx_13, u_df, by = "umpire")
### --- Rearrange variables --- ###
pfx_13 <- pfx_13 %>%
select(c(gameday_link, batter_name, b_height, stand, sz_top, sz_bot,
player_sz_top, player_sz_bot, height_top, height_bot, px, pz,
count, bs_count, h_dist, h_mid, v_dist, zone, zone_reg,
umpire, yr_exp = yr_exp.y, call, u_test))
### --- Rearrange variables --- ###
pfx_13 <- pfx_13 %>%
select(c(gameday_link, batter_name, b_height, stand, sz_top, sz_bot,
player_sz_top, player_sz_bot, height_top, height_bot, px, pz,
count, bs_count, h_dist, h_mid, v_dist, zone, zone_reg,
umpire, yr_exp, call, u_test))
glimpse(pfx_13)
save(pfx_13, file = "~/Desktop/pfx_13.rda")
